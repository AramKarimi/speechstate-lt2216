{"version":3,"sources":["dmColourChanger.ts","index.tsx"],"names":["sayColour","send","context","type","value","recResult","say","text","_context","dmMachine","initial","states","init","on","CLICK","welcome","RECOGNISED","target","prompt","entry","ENDSPEECH","ask","stop","always","repaint","myTTS","speechSynthesis","myTTSUtterance","SpeechSynthesisUtterance","TOKEN_ENDPOINT","REGION","a","fetch","method","headers","process","response","authorizationToken","createPonyfill","credentials","region","ponyfill","inspect","url","iframe","actions","cancel","machine","Machine","id","dm","asrtts","idle","LISTEN","SPEAK","assign","event","ttsAgenda","recognising","exit","ASRRESULT","noinput","delay","TIMEOUT","STARTSPEECH","inprogress","match","speaking","recLogResult","console","log","test","logIntent","nluData","intent","name","ReactiveButton","props","state","matches","className","style","animation","App","React","createSpeechRecognitionPonyfill","AzureSpeechRecognition","SpeechRecognition","applyPolyfill","getRecognition","onresult","results","result","isFinal","transcript","confidence","fetchASRTTS","useMachine","devTools","recStart","asEffect","startListening","continuous","language","recStop","stopListening","ttsStart","voices","getVoices","utterance","voice","find","onend","speak","ttsCancel","current","onClick","rootElement","document","getElementById","ReactDOM"],"mappings":"ofAGMA,EAA0CC,aAAK,SAACC,GAAD,MAA0B,CAC3EC,KAAM,QAASC,MAAM,iBAAD,OAAmBF,EAAQG,eAGnD,SAASC,EAAIC,GACT,OAAON,aAAK,SAACO,GAAD,MAA2B,CAAEL,KAAM,QAASC,MAAOG,MAG5D,IAAME,EAAuD,CAChEC,QAAS,OACTC,OAAQ,CACJC,KAAM,CACFC,GAAI,CACAC,MAAO,YAGfC,QAAS,CACLL,QAAS,SACTG,GAAI,CACAG,WAAY,CAER,CAAEC,OAAQ,aAElBN,OAAQ,CACJO,OAAQ,CACJC,MAAOb,EAAI,sBACXO,GAAI,CAAEO,UAAW,QAErBC,IAAK,CACDF,MAAOlB,YAAK,aAIxBqB,KAAM,CACFH,MAAOb,EAAI,MACXiB,OAAQ,QAEZC,QAAS,CACLd,QAAS,SACTC,OAAQ,CACJO,OAAQ,CACJC,MAAOnB,EACPa,GAAI,CAAEO,UAAW,YAErBI,QAAS,CACLL,MAAO,eACPI,OAAQ,wB,QCnCxBE,EAAQC,gBACRC,EAAiBC,yBAEfC,EAAiB,sEACjBC,EAAS,cAEf,sBAAC,oCAAAC,EAAA,+EAE8BC,MAAMH,EAAgB,CACzCI,OAAQ,OACRC,QAAS,CAAE,4BAA6BC,sCAJnD,cAEaC,EAFb,gBAMwCA,EAAS7B,OANjD,cAMa8B,EANb,gBAQ8BC,IAAe,CAClCC,YAAa,CACTC,OAAQV,EACRO,mBAAoBA,KAXnC,OAQaI,EARb,OAcef,EAA8Ce,EAA9Cf,gBAAiBE,EAA6Ba,EAA7Bb,yBACzBH,EAAQC,EACRC,EAAiBC,EAhBxB,2GAAD,GAqBAc,YAAQ,CACJC,IAAK,iCACLC,QAAQ,IAGZ,IAAQ3C,EAAiB4C,IAAjB5C,KAAM6C,EAAWD,IAAXC,OAIRC,EAAUC,YAAmC,CAC/CC,GAAI,OACJ9C,KAAM,WACNQ,OAAQ,CACJuC,GAAG,eACIzC,GAGP0C,OAAQ,CACJzC,QAAS,OACTC,OAAQ,CACJyC,KAAM,CACFvC,GAAI,CACAwC,OAAQ,cACRC,MAAO,CACHrC,OAAQ,WACR4B,QAASU,aAAO,SAAC/C,EAAUgD,GAAY,MAAO,CAAEC,UAAWD,EAAMpD,aAI7EsD,YAAa,CACThD,QAAS,UACTS,MAAO,WACPwC,KAAM,UACN9C,GAAI,CACA+C,UAAW,CACPf,QAAS,CAAC,eACNU,aAAO,SAAC/C,EAAUgD,GACd,MAAO,CACHnD,UAAWmD,EAAMpD,WAG7Ba,OAAQ,UAEZD,WAAY,QAEhBL,OAAQ,CACJkD,QAAS,CACL1C,MAAOlB,EACH,CAAEE,KAAM,WACR,CAAE2D,MAAO,SAAC5D,GAAD,OAAc,KAAoD+C,GAAI,YAEnFpC,GAAI,CACAkD,QAAS,oBACTC,YAAa,cAEjBL,KAAMb,EAAO,YAEjBmB,WAAY,GAEZC,MAAO,CACH/C,MAAOlB,EAAK,iBAIxBkE,SAAU,CACNhD,MAAO,WACPN,GAAI,CACAO,UAAW,aAO/B,CACIyB,QAAS,CACLuB,aAAc,SAAClE,GAEXmE,QAAQC,IAAI,WAAapE,EAAQG,UAAU,GAAlB,YAE7BkE,KAAM,WACFF,QAAQC,IAAI,SAEhBE,UAAW,SAACtE,GAERmE,QAAQC,IAAI,kBAAoBpE,EAAQuE,QAAQC,OAAOC,UAUjEC,EAAiB,SAACC,GACpB,QAAQ,GACJ,KAAKA,EAAMC,MAAMC,QAAQ,CAAE5B,OAAQ,gBAC/B,OACI,gDAAQhD,KAAK,SAAS6E,UAAU,gBAC5BC,MAAO,CAAEC,UAAW,uBAA4BL,GADpD,+BAKR,KAAKA,EAAMC,MAAMC,QAAQ,CAAE5B,OAAQ,aAC/B,OACI,gDAAQhD,KAAK,SAAS6E,UAAU,gBAC5BC,MAAO,CAAEC,UAAW,0BAA+BL,GADvD,8BAKR,KAAKA,EAAMC,MAAMC,QAAQ,CAAE7B,GAAI,SAC3B,OACI,gDAAQ/C,KAAK,SAAS6E,UAAU,iBACxBH,GADR,2CAMR,QACI,OACI,gDAAQ1E,KAAK,SAAS6E,UAAU,iBAAoBH,GAApD,mCAShB,SAASM,IAYLC,aAAgB,WAAM,4CAClB,kCAAArD,EAAA,sEAC2BC,MAAMH,EAAgB,CACzCI,OAAQ,OACRC,QAAS,CAAE,4BAA6BC,sCAHhD,cACUC,EADV,gBAKqCA,EAAS7B,OAL9C,cAKU8B,EALV,gBAQoBgD,IAAgC,CACpC9C,YAAa,CACTC,OAAQV,EACRO,mBAAoBA,KAXxC,gBAO6BiD,EAP7B,EAOUC,kBAONA,IAAkBC,cAAcF,GACpBC,IAAkBE,iBACzBC,SAAW,SAASlC,GACrBa,QAAQC,IAAId,EAAMmC,SAClB,IAAIC,EAASpC,EAAMmC,QAAQ,GACvBC,EAAOC,QACP5F,EAAK,CACDE,KAAM,YAAaC,MACf,CAAC,CACG,UAAawF,EAAO,GAAGE,WACvB,WAAcF,EAAO,GAAGG,eAIpC9F,EAAK,CAAEE,KAAM,iBA5BzB,6CADkB,uBAAC,WAAD,wBAiClB6F,KACD,IAIH,MAAiCC,YAAWlD,EAAS,CACjDmD,UAAU,EACVrD,QAAS,CACLsD,SAAUC,aAAS,WACf/B,QAAQC,IAAI,mCAnDpBiB,IAAkBc,eAAe,CAC7BC,YAAY,EACZC,SAAU,aAqDVC,QAASJ,aAAS,WACd/B,QAAQC,IAAI,wBAlDpBiB,IAAkBkB,mBAqDdC,SAAUN,aAAS,SAAClG,GAChBmE,QAAQC,IAAI,eACZ,IAAMqC,EAASlF,EAAMmF,YACrBvC,QAAQC,IAAIqC,GACZ,IAAME,EAAY,IAAIlF,EAAezB,EAAQuD,WAC7CoD,EAAUC,MAAQH,EAAOI,MAAK,SAAAD,GAAK,MAAI,yBAAoBvC,KAAKuC,EAAMnC,SACtEkC,EAAUG,MAAQ,kBAAM/G,EAAK,cAC7BwB,EAAMwF,MAAMJ,MAEhBK,UAAWd,aAAS,WAChB/B,QAAQC,IAAI,eAEZ5C,gBAAgBoB,eAxB5B,mBAAOqE,EAAP,KAAgBlH,EAAhB,UAkCA,OACI,qBAAK+E,UAAU,MAAf,SACI,cAAC,EAAD,CAAgBF,MAAOqC,EAASC,QAAS,kBAAMnH,EAAK,cAOhE,IAAMoH,EAAcC,SAASC,eAAe,QAC5CC,SACI,cAACrC,EAAD,IACAkC,K","file":"static/js/main.01970ea9.chunk.js","sourcesContent":["import { MachineConfig, send, Action } from \"xstate\";\n\n\nconst sayColour: Action<SDSContext, SDSEvent> = send((context: SDSContext) => ({\n    type: \"SPEAK\", value: `Repainting to ${context.recResult}`\n}))\n\nfunction say(text: string): Action<SDSContext, SDSEvent> {\n    return send((_context: SDSContext) => ({ type: \"SPEAK\", value: text }))\n}\n\nexport const dmMachine: MachineConfig<SDSContext, any, SDSEvent> = ({\n    initial: 'init',\n    states: {\n        init: {\n            on: {\n                CLICK: 'welcome'\n            }\n        },\n        welcome: {\n            initial: 'prompt',\n            on: {\n                RECOGNISED: [\n                    // { target: 'stop', cond: (context) => context.recResult === 'stop' },\n                    { target: 'repaint' }]\n            },\n            states: {\n                prompt: {\n                    entry: say(\"Tell me the colour\"),\n                    on: { ENDSPEECH: 'ask' }\n                },\n                ask: {\n                    entry: send('LISTEN'),\n                },\n            }\n        },\n        stop: {\n            entry: say(\"Ok\"),\n            always: 'init'\n        },\n        repaint: {\n            initial: 'prompt',\n            states: {\n                prompt: {\n                    entry: sayColour,\n                    on: { ENDSPEECH: 'repaint' }\n                },\n                repaint: {\n                    entry: 'changeColour',\n                    always: '#root.dm.welcome'\n                }\n            }\n        }\n    }\n})\n","import \"./styles.scss\";\nimport * as React from \"react\";\nimport * as ReactDOM from \"react-dom\";\nimport { Machine, assign, actions, State } from \"xstate\";\nimport { useMachine, asEffect } from \"@xstate/react\";\nimport { inspect } from \"@xstate/inspect\";\nimport SpeechRecognition from 'react-speech-recognition';\n\nimport createSpeechRecognitionPonyfill from 'web-speech-cognitive-services/lib/SpeechServices/SpeechToText'\nimport createPonyfill from 'web-speech-cognitive-services/lib/SpeechServices';\n\n/* import { dmMachine } from \"./tdmClient\"; */\nimport { dmMachine } from \"./dmColourChanger\";\n\nvar myTTS = speechSynthesis;\nvar myTTSUtterance = SpeechSynthesisUtterance;\n\nconst TOKEN_ENDPOINT = 'https://northeurope.api.cognitive.microsoft.com/sts/v1.0/issuetoken';\nconst REGION = 'northeurope';\n\n(async function() {\n    try {\n        const response = await fetch(TOKEN_ENDPOINT, {\n            method: 'POST',\n            headers: { 'Ocp-Apim-Subscription-Key': process.env.REACT_APP_SUBSCRIPTION_KEY! }\n        });\n        const authorizationToken = await response.text();\n\n        const ponyfill = await createPonyfill({\n            credentials: {\n                region: REGION,\n                authorizationToken: authorizationToken,\n            }\n        });\n        const { speechSynthesis, SpeechSynthesisUtterance } = ponyfill;\n        myTTS = speechSynthesis;\n        myTTSUtterance = SpeechSynthesisUtterance;\n    } catch (e) { }\n})();\n\n\ninspect({\n    url: \"https://statecharts.io/inspect\",\n    iframe: false\n});\n\nconst { send, cancel } = actions;\n\nconst defaultPassivity = 5\n\nconst machine = Machine<SDSContext, any, SDSEvent>({\n    id: 'root',\n    type: 'parallel',\n    states: {\n        dm: {\n            ...dmMachine\n        },\n\n        asrtts: {\n            initial: 'idle',\n            states: {\n                idle: {\n                    on: {\n                        LISTEN: 'recognising',\n                        SPEAK: {\n                            target: 'speaking',\n                            actions: assign((_context, event) => { return { ttsAgenda: event.value } })\n                        }\n                    }\n                },\n                recognising: {\n                    initial: 'noinput',\n                    entry: 'recStart',\n                    exit: 'recStop',\n                    on: {\n                        ASRRESULT: {\n                            actions: ['recLogResult',\n                                assign((_context, event) => {\n                                    return {\n                                        recResult: event.value\n                                    }\n                                })],\n                            target: '.match'\n                        },\n                        RECOGNISED: 'idle',\n                    },\n                    states: {\n                        noinput: {\n                            entry: send(\n                                { type: 'TIMEOUT' },\n                                { delay: (context) => (1000 * (defaultPassivity || context.tdmPassivity)), id: 'timeout' }\n                            ),\n                            on: {\n                                TIMEOUT: '#root.asrtts.idle',\n                                STARTSPEECH: 'inprogress'\n                            },\n                            exit: cancel('timeout')\n                        },\n                        inprogress: {\n                        },\n                        match: {\n                            entry: send('RECOGNISED'),\n                        },\n                    }\n                },\n                speaking: {\n                    entry: 'ttsStart',\n                    on: {\n                        ENDSPEECH: 'idle',\n                    }\n                }\n            }\n        }\n    },\n},\n    {\n        actions: {\n            recLogResult: (context: SDSContext) => {\n                /* context.recResult = event.recResult; */\n                console.log('<< ASR: ' + context.recResult[0][\"utterance\"]);\n            },\n            test: () => {\n                console.log('test')\n            },\n            logIntent: (context: SDSContext) => {\n                /* context.nluData = event.data */\n                console.log('<< NLU intent: ' + context.nluData.intent.name)\n            }\n        },\n    });\n\n\n\ninterface Props extends React.HTMLAttributes<HTMLElement> {\n    state: State<SDSContext, any, any, any>;\n}\nconst ReactiveButton = (props: Props): JSX.Element => {\n    switch (true) {\n        case props.state.matches({ asrtts: 'recognising' }):\n            return (\n                <button type=\"button\" className=\"glow-on-hover\"\n                    style={{ animation: \"glowing 20s linear\" }} {...props}>\n                    Listening...\n                </button>\n            );\n        case props.state.matches({ asrtts: 'speaking' }):\n            return (\n                <button type=\"button\" className=\"glow-on-hover\"\n                    style={{ animation: \"bordering 1s infinite\" }} {...props}>\n                    Speaking...\n                </button>\n            );\n        case props.state.matches({ dm: 'fail' }):\n            return (\n                <button type=\"button\" className=\"glow-on-hover\"\n                    {...props}>\n                    FAILURE! reload the page\n                </button>\n            );\n\n        default:\n            return (\n                <button type=\"button\" className=\"glow-on-hover\" {...props}>\n                    Click to start\n                </button >\n            );\n    }\n}\n\n\n\nfunction App() {\n\n    const startListening = () => {\n        SpeechRecognition.startListening({\n            continuous: true,\n            language: 'en-US'\n        });\n    }\n    const stopListening = () => {\n        SpeechRecognition.stopListening()\n    }\n\n    React.useEffect(() => {\n        async function fetchASRTTS() {\n            const response = await fetch(TOKEN_ENDPOINT, {\n                method: 'POST',\n                headers: { 'Ocp-Apim-Subscription-Key': process.env.REACT_APP_SUBSCRIPTION_KEY! }\n            });\n            const authorizationToken = await response.text();\n            const\n                { SpeechRecognition: AzureSpeechRecognition }\n                    = await createSpeechRecognitionPonyfill({\n                        credentials: {\n                            region: REGION,\n                            authorizationToken: authorizationToken,\n                        }\n                    });\n            SpeechRecognition.applyPolyfill(AzureSpeechRecognition)\n            const rec = SpeechRecognition.getRecognition()\n            rec!.onresult = function(event: any) {\n                console.log(event.results)\n                var result = event.results[0]\n                if (result.isFinal) {\n                    send({\n                        type: \"ASRRESULT\", value:\n                            [{\n                                \"utterance\": result[0].transcript,\n                                \"confidence\": result[0].confidence\n                            }]\n                    })\n                } else {\n                    send({ type: \"STARTSPEECH\" });\n                }\n            }\n        }\n        fetchASRTTS()\n    }, []\n    )\n\n\n    const [current, send, service] = useMachine(machine, {\n        devTools: true,\n        actions: {\n            recStart: asEffect(() => {\n                console.log('Ready to receive a voice input.');\n                startListening()\n                /* speechRecognition.start() */\n            }),\n            recStop: asEffect(() => {\n                console.log('Recognition stopped.');\n                stopListening()\n            }),\n            ttsStart: asEffect((context) => {\n                console.log('Speaking...');\n                const voices = myTTS.getVoices();\n                console.log(voices)\n                const utterance = new myTTSUtterance(context.ttsAgenda);\n                utterance.voice = voices.find(voice => /en-US-AriaNeural/u.test(voice.name))!\n                utterance.onend = () => send('ENDSPEECH')\n                myTTS.speak(utterance)\n            }),\n            ttsCancel: asEffect(() => {\n                console.log('TTS STOP...');\n                /* cancel() */\n                speechSynthesis.cancel()\n            })\n            /* speak: asEffect((context) => {\n             * console.log('Speaking...');\n             *     speak({text: context.ttsAgenda })\n             * } */\n        }\n    });\n\n\n    return (\n        <div className=\"App\">\n            <ReactiveButton state={current} onClick={() => send('CLICK')} />\n        </div>\n    )\n};\n\n\n\nconst rootElement = document.getElementById(\"root\");\nReactDOM.render(\n    <App />,\n    rootElement);\n\n\n"],"sourceRoot":""}